#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆä½µé æ¸¬çµæœåˆ°åŸå§‹æª”æ¡ˆçš„è…³æœ¬
"""

import pandas as pd
import numpy as np
import os
import glob

def merge_predictions_to_original_files():
    """
    å°‡ _logs ç›®éŒ„ä¸­çš„é æ¸¬çµæœåˆä½µåˆ°åŸå§‹æª”æ¡ˆä¸­
    """
    
    # è¨­å®šè·¯å¾‘
    logs_dir = "./_logs/bed_monitor_test_sum"
    original_data_dir = "./_data/pyqt_viewer"
    
    # å°‹æ‰¾æ‰€æœ‰é æ¸¬çµæœæª”æ¡ˆ
    prediction_files = glob.glob(os.path.join(logs_dir, "predictions_*.csv"))
    
    if not prediction_files:
        print("âŒ åœ¨ logs ç›®éŒ„ä¸­æœªæ‰¾åˆ°é æ¸¬çµæœæª”æ¡ˆ")
        print(f"è«‹ç¢ºèª {logs_dir} ç›®éŒ„ä¸­æ˜¯å¦æœ‰ predictions_*.csv æª”æ¡ˆ")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(prediction_files)} å€‹é æ¸¬çµæœæª”æ¡ˆ:")
    for file in prediction_files:
        print(f"  - {os.path.basename(file)}")
    
    successful_merges = 0
    
    for pred_file in prediction_files:
        try:
            # å¾é æ¸¬æª”æ¡ˆåç¨±ä¸­æå–åŸå§‹æª”æ¡ˆåç¨±
            # predictions_æª”æ¡ˆåç¨±.csv -> æª”æ¡ˆåç¨±.csv
            base_name = os.path.basename(pred_file)
            original_filename = base_name.replace("predictions_", "")
            original_file_path = os.path.join(original_data_dir, original_filename)
            
            print(f"\nğŸ”„ è™•ç†: {original_filename}")
            
            # æª¢æŸ¥åŸå§‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨
            if not os.path.exists(original_file_path):
                print(f"âŒ åŸå§‹æª”æ¡ˆä¸å­˜åœ¨: {original_file_path}")
                continue
            
            # è®€å–é æ¸¬çµæœ
            pred_df = pd.read_csv(pred_file)
            print(f"ğŸ“Š é æ¸¬çµæœ: {pred_df.shape[0]} è¡Œ, æ¬„ä½: {list(pred_df.columns)}")
            
            # è®€å–åŸå§‹æª”æ¡ˆ
            original_df = pd.read_csv(original_file_path)
            print(f"ğŸ“Š åŸå§‹æª”æ¡ˆ: {original_df.shape[0]} è¡Œ, {original_df.shape[1]} æ¬„")
            
            # æª¢æŸ¥é æ¸¬çµæœæ ¼å¼
            if 'Predicted' not in pred_df.columns:
                print("âš ï¸  é æ¸¬çµæœæª”æ¡ˆä¸­æ²’æœ‰ 'Predicted' æ¬„ä½ï¼Œå˜—è©¦ä½¿ç”¨ 'Predicted' æ¬„ä½...")
                if 'Predicted' in pred_df.columns:
                    # å‡è¨­ 'Predicted' æ¬„ä½æ˜¯é æ¸¬æ©Ÿç‡å€¼
                    pred_probs = pred_df['Predicted'].values
                else:
                    print("âŒ ç„¡æ³•æ‰¾åˆ°é æ¸¬æ©Ÿç‡å€¼")
                    continue
            else:
                pred_probs = pred_df['Predicted'].values
            
            # è¨ˆç®—æœ€ä½³é–¾å€¼ï¼ˆä½¿ç”¨ç°¡å–®çš„æ–¹æ³•ï¼‰
            threshold = np.percentile(pred_probs, 95)  # ä½¿ç”¨95ç™¾åˆ†ä½ä½œç‚ºé–¾å€¼
            pred_binary = (pred_probs > threshold).astype(int)
            
            print(f"ğŸ¯ ä½¿ç”¨é–¾å€¼: {threshold:.4f}")
            print(f"ğŸ“ˆ é æ¸¬ç‚ºæ­£ä¾‹çš„æ•¸é‡: {np.sum(pred_binary)}")
            
            # ç¢ºä¿é•·åº¦ä¸€è‡´
            min_length = min(len(original_df), len(pred_probs))
            
            # æ·»åŠ é æ¸¬çµæœåˆ°åŸå§‹æª”æ¡ˆ
            # å¦‚æœå·²ç¶“æœ‰é€™äº›æ¬„ä½ï¼Œå…ˆåˆªé™¤
            if 'Predicted' in original_df.columns:
                original_df = original_df.drop(columns=['Predicted'])
            if 'Predicted_Prob' in original_df.columns:
                original_df = original_df.drop(columns=['Predicted_Prob'])
            
            # æ·»åŠ æ–°çš„é æ¸¬çµæœ
            original_df.loc[:min_length-1, 'Predicted'] = pred_binary[:min_length]
            original_df.loc[:min_length-1, 'Predicted_Prob'] = pred_probs[:min_length]
            
            # ç‚ºæ²’æœ‰é æ¸¬çµæœçš„è¡Œå¡«å…¥é è¨­å€¼
            original_df['Predicted'] = original_df['Predicted'].fillna(0).astype(int)
            original_df['Predicted_Prob'] = original_df['Predicted_Prob'].fillna(0.0)
            
            # å‚™ä»½åŸå§‹æª”æ¡ˆ
            backup_path = original_file_path + ".backup"
            if not os.path.exists(backup_path):
                original_df_backup = pd.read_csv(original_file_path)
                original_df_backup.to_csv(backup_path, index=False)
                print(f"ğŸ’¾ å·²å»ºç«‹å‚™ä»½æª”æ¡ˆ: {backup_path}")
            
            # ä¿å­˜åˆä½µå¾Œçš„æª”æ¡ˆ
            original_df.to_csv(original_file_path, index=False)
            print(f"âœ… æˆåŠŸåˆä½µé æ¸¬çµæœåˆ°: {original_file_path}")
            print(f"ğŸ“Š æœ€çµ‚æª”æ¡ˆ: {original_df.shape[0]} è¡Œ, {original_df.shape[1]} æ¬„")
            
            successful_merges += 1
            
        except Exception as e:
            print(f"âŒ è™•ç† {os.path.basename(pred_file)} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\nğŸ‰ å®Œæˆï¼æˆåŠŸåˆä½µ {successful_merges} å€‹æª”æ¡ˆ")
    
    if successful_merges > 0:
        print("\nğŸ“ æ³¨æ„äº‹é …:")
        print("1. åŸå§‹æª”æ¡ˆå·²è¢«ä¿®æ”¹ï¼Œå‚™ä»½æª”æ¡ˆä½æ–¼åŒä¸€ç›®éŒ„ä¸‹ (.backup å‰¯æª”å)")
        print("2. æ·»åŠ äº†å…©å€‹æ–°æ¬„ä½:")
        print("   - Predicted: äºŒé€²åˆ¶é æ¸¬çµæœ (0/1)")
        print("   - Predicted_Prob: é æ¸¬æ©Ÿç‡å€¼ (0.0-1.0)")

if __name__ == "__main__":
    merge_predictions_to_original_files() 